{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a5c87-7904-44bc-88ce-5fa377a654b7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "- Wiley Winters\n",
    "- MSDS 686 Deep Learning\n",
    "- Week 7-8 Kaggle Project&nbsp;&mdash;&nbsp;Brain Tumor Classification\n",
    "- 2025-MAR-\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05873db-0aad-476d-8b41-bd62b38fbe2c",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b5d5-8ee4-487d-b812-9e651e8f0411",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "**Required for 80%**</p>\n",
    "Complete project on *kaggle.com* using the skills learned in the <u>Deep Learning</u> class.  The following are required:\n",
    "- Show/plot sample images or data with labels\n",
    "- Include at least on of the following\n",
    "  - Convolution\n",
    "  - Max Pooling\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  - LSTM\n",
    "  - TF-IDf\n",
    "- Use validation data\n",
    "- Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333805a-2b73-4173-89af-5e8f15c229dc",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "**Additional for another 20%**</p>\n",
    "- Use data augmentation\n",
    "- Use at least one of the following:\n",
    "  - Kernels\n",
    "  - Activation functions\n",
    "  - Loss functions\n",
    "  - Libraries\n",
    "  - Methods\n",
    "- Learning rate optimization\n",
    "- Functional API model\n",
    "- Transfer learning with or without trainable parameters\n",
    "- Confusion matrix and / or ROC plots\n",
    "- Plots of accuracy/loss vs epochs\n",
    "- Show/plot sample incorrect prediction with labels and correct label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ff122-b739-4898-b7c2-7da8051f4c91",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "### Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b571d24-526c-4b90-84b1-d1f484d67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, pathlib, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# Import openCV and Pillow APIs\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "# Libraries for general machine learning tasks and measuring performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch API\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Module, Conv2d, Linear, MaxPool2d, ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "from torch import optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "# Print status bars\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Make plots have guidelines\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de47652f-0de2-47d8-8893-53d8071cd66f",
   "metadata": {},
   "source": [
    "**Set Random Seed for Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5690f5b-2668-4170-84a4-b54d50285f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eda37e-7ecf-4bf1-8225-86568f4225df",
   "metadata": {},
   "source": [
    "**Declare Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cd018-0c6c-4508-999b-8e656ab24c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Directories\n",
    "home_dir = '/home/wiley/regis/dataScience'\n",
    "trn_dir = home_dir+'/msds686/week7/kaggleProject/images/data/training'\n",
    "tst_dir = home_dir+'/msds686/week7/kaggleProject/images/data/testing'\n",
    "val_dir = home_dir+'/msds686/week7/kaggleProject/images/data/validation'\n",
    "\n",
    "# Create path objects\n",
    "home_dir = pathlib.Path(home_dir)\n",
    "trn_dir = pathlib.Path(tst_dir)\n",
    "val_dir = pathlib.Path(val_dir)\n",
    "\n",
    "# Classes\n",
    "classes = ['negative', 'positive']\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Image size and shape\n",
    "img_size = (256, 256)\n",
    "img_shape = (256, 256, 3)\n",
    "\n",
    "# Make sure pyTorch uses GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a9794-8027-4dde-a59f-65c064ca6808",
   "metadata": {},
   "source": [
    "**Define Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71683525-d7fc-497b-a783-3a2fa49af404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance Metrics\n",
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle('Model Training Metrics over Epochs', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fdea34-3182-4791-8d1a-f7259ce000fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results from test data\n",
    "def print_test(model, test_data, test_labels):\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "    print('---------------------------------------------------')\n",
    "    print('\\033[1m'+'Test results:'+'\\033[0m')\n",
    "    print(f'Test loss:{round(test_loss,4)}')\n",
    "    print(f'Test accuracy:{round(test_acc,4)}')\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbba28-2cc8-4493-88c8-feed19f07d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the output size of\n",
    "# of a convolutional layer in a NN\n",
    "def findConv2dOutShape(hin, win, conv, pool=2):\n",
    "    # get conv arguments\n",
    "    kernel_size = conv.kernel_size\n",
    "    stride = conv.stride\n",
    "    padding = conv.padding\n",
    "    dilation = conv.dilation\n",
    "\n",
    "    hout = np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    wout = np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout /= pool\n",
    "        wout /= pool\n",
    "    return int(hout), int(wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38413c44-0601-444c-bf5f-5d04ce363421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the learning rate\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73dde7-cfb8-4b81-802d-bb68766707b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the loss value per batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    metric_b = pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52b9dd-a3b8-492f-8825-92206f8fd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the loss value and performance per batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    metric_b = pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8552df-51bf-4ac9-8415-2aecaca08ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the loss and performance per epoch\n",
    "def loss_epoch(model, loss_func, dataset_dl, opt=None):\n",
    "    run_loss = 0.0 \n",
    "    t_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "        loss_b,metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "        run_loss += loss_b\n",
    "\n",
    "        if metric_b is not None:\n",
    "            t_metric += metric_b    \n",
    "    \n",
    "    loss = run_loss/float(len_data)\n",
    "    metric = t_metric/float(len_data)\n",
    "    \n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972108f-f40a-4388-8f4e-6c5c35d394b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Function\n",
    "def train_val(model, params, verbose=False):\n",
    "    epochs = params['epochs']\n",
    "    loss_func = params['f_loss']\n",
    "    opt = params['optimizer']\n",
    "    train_dl = params['train']\n",
    "    val_dl = params['val']\n",
    "    lr_scheduler = params['lr_change']\n",
    "    weight_path = params['weight_path']\n",
    "    \n",
    "    loss_history = {'train': [], 'val': []} \n",
    "    metric_history = {'train': [], 'val': []} \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "    best_loss = float('inf') \n",
    "\n",
    "    # Train Model n_epochs (the progress of training by printing the epoch number \n",
    "    # and the associated learning rate. \n",
    "    # It can be helpful for debugging, monitoring the learning rate schedule, \n",
    "    # or gaining insights into the training process.) \n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # Get the Learning Rate\n",
    "        current_lr = get_lr(opt)\n",
    "        if(verbose):\n",
    "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n",
    " \n",
    "       # Train Model Process\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n",
    "\n",
    "        # collect losses\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "        \n",
    "        # Evaluate Model Process\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n",
    "        \n",
    "        # store best model\n",
    "        if(val_loss < best_loss):\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # store weights into a local file\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "            if(verbose):\n",
    "                print('Copied best model weights!')\n",
    "        \n",
    "        # collect loss and metric for validation dataset\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "        \n",
    "        # learning rate schedule\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            if(verbose):\n",
    "                print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts) \n",
    "\n",
    "        if(verbose):\n",
    "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
    "            print(\"-\"*10) \n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "        \n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1579e6-53ed-4a01-8f86-a94c6079d958",
   "metadata": {},
   "source": [
    "### Define Binary Classifier\n",
    "This model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e89f12-3e4a-4454-846b-07684af02b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_tumor(nn.Module):\n",
    "    \n",
    "    # Network Initialization\n",
    "    def __init__(self, params):\n",
    "        super(cnn_tumor, self).__init__()\n",
    "        Cin,Hin,Win = params['shape_in']\n",
    "        init_f = params['initial_filters'] \n",
    "        num_fc1 = params['num_fc1']  \n",
    "        num_classes = params['num_classes'] \n",
    "        self.dropout_rate = params['dropout_rate'] \n",
    "        \n",
    "        # Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
    "        h, w = findConv2dOutShape(Hin, Win, self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "        h, w = findConv2dOutShape(h, w, self.conv2)\n",
    "        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "        h, w = findConv2dOutShape(h, w, self.conv3)\n",
    "        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "        h, w = findConv2dOutShape(h, w, self.conv4)\n",
    "        \n",
    "        # compute the flatten size\n",
    "        self.num_flatten = h*w*8*init_f\n",
    "        #self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc1 = nn.Linear(12544, 64)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        # Convolution & Pool Layers\n",
    "        X = F.relu(self.conv1(X)); \n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        #X = X.view(-1, self.num_flatten)\n",
    "        X = X.view(X.size(0), -1)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.dropout(X, self.dropout_rate)\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e51bf-ce68-418a-95d9-e2bd061af0e5",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The method used to load paths and classes into the dataframes will go from director to directory.  In other words, there will be artificial groupings of the different brain tumor classes.  I added statements to shuffle the values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68e32f-2bd3-45c4-a391-2830c3d44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into a pandas dataframe for EDA\n",
    "labels, paths = zip(*[(label, os.path.join(trn_dir, label, image))\n",
    "                       for label in os.listdir(trn_dir)\n",
    "                       if os.path.isdir(os.path.join(trn_dir, label))\n",
    "                       for image in os.listdir(os.path.join(trn_dir, label))])\n",
    "\n",
    "trn_df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "\n",
    "# Load testing data into a pandas dataframe for EDA\n",
    "labels, paths = zip(*[(label, os.path.join(tst_dir, label, image))\n",
    "                       for label in os.listdir(tst_dir)\n",
    "                       if os.path.isdir(os.path.join(tst_dir, label))\n",
    "                       for image in os.listdir(os.path.join(tst_dir, label))])\n",
    "\n",
    "tst_df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "\n",
    "# Load validation data into pandas dataframe for EDA\n",
    "labels, paths = zip(*[(label, os.path.join(val_dir, label, image))\n",
    "                       for label in os.listdir(val_dir)\n",
    "                       if os.path.isdir(os.path.join(val_dir, label))\n",
    "                       for image in os.listdir(os.path.join(val_dir, label))])\n",
    "\n",
    "val_df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "\n",
    "# Shuffle the training and testing dataframes\n",
    "trn_df = trn_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "tst_df = tst_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Take a look at the results\n",
    "print('Training:\\n', trn_df.head(10).to_markdown())\n",
    "print('Testing:\\n', tst_df.head(10).to_markdown())\n",
    "print('Validation:\\n', val_df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9db2-c2c8-47bd-b7e8-f8e560893cbb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2877-8ac2-4ec1-9538-058148afa3b4",
   "metadata": {},
   "source": [
    "**Look at Training Images' Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb55660-1fb9-4659-b035-4d0fef96020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-->Training Labels Value Counts:\\n', trn_df['labels'].value_counts())\n",
    "print('-->Testing Labels Value Counts:\\n', tst_df['labels'].value_counts())\n",
    "print('-->Validation Lables Value Counts:\\n', val_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfd0c-6a4f-467f-b2db-9660ef784211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "trn_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83417025-01e6-4455-8da6-4b296105fd5b",
   "metadata": {},
   "source": [
    "The distribution is a little unbalanced and I may have to perform some mitigation efforts to fix this, but will continue with this analysis as is for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58827-788f-4a7f-b3cc-d3e1c5b1794c",
   "metadata": {},
   "source": [
    "**Look at Testing Images' Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721c78-2fe1-4ead-9893-719aa5358cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "tst_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Testing Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45b538-95f6-4941-b788-911279995810",
   "metadata": {},
   "source": [
    "Distribution mirrors what the *training data* shows, but with less frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df83bf6-7d8d-4e43-b697-64d967efdb8f",
   "metadata": {},
   "source": [
    "<span style='color:orange'>NOTE:</span>&nbsp;&nbsp;The classes are unbalance and will have to be handled before fitting the data to the model.  There are a few methods I can use to balance the classes:\n",
    "- Resampling Techniques\n",
    "  - Oversampling\n",
    "  - Under-sampling\n",
    "- Class Weighting\n",
    "  - Weighted Loss Functions\n",
    "  - Weighted Random Sampler\n",
    "- Synthetic Data Generation\n",
    "  - SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "  - GANs (Generative Adversarial Networks)\n",
    "\n",
    "I can also use the ***F1 Score*** which is not influences as much by unbalanced classes as the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9268e-735f-4c8f-8eda-b90d7766f17a",
   "metadata": {},
   "source": [
    "**Examine Shape of Training and Testing DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbc83e-c39f-4fa3-be99-77ce26ea9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Shape: \\n', trn_df.shape)\n",
    "print('Testing Shape:  \\n', tst_df.shape)\n",
    "print('Validation Shape: \\n', val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8aa5-b7de-4a72-9fcc-7621af79763f",
   "metadata": {},
   "source": [
    "**NOTE:**&nbsp;&nbsp;Since the dataframes are built from the contents of the image directories, there should be no missing values or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e147d77-1ae2-418c-9d9a-943c6529ebc0",
   "metadata": {},
   "source": [
    "### Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b32df-808b-4c56-a8d9-40b36d7dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform object\n",
    "transf = transforms.Compose([\n",
    "    transforms.Resize((img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.458, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define objects for training, testing, and validation datasets\n",
    "trn_ds = torchvision.datasets.ImageFolder(trn_dir, transform=transf)\n",
    "trn_ds.transform = transf\n",
    "\n",
    "# Testing images should not be augmented\n",
    "tst_ds = torchvision.datasets.ImageFolder(tst_dir, transform=transforms.ToTensor())\n",
    "tst_ds.transform\n",
    "\n",
    "val_ds = torchvision.datasets.ImageFolder(val_dir, transform=transf)\n",
    "val_ds.transform = transf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02d30d-82be-45f4-803d-f2641aed7682",
   "metadata": {},
   "source": [
    "### Visualize some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198c991-55c1-4474-917e-ebe3d9db6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = {0: 'positive', 1: 'negative'}\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "cols, rows = 4, 4\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(trn_ds), size=(1,)).item()\n",
    "    img, label = trn_ds[sample_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.title(class_label[label])\n",
    "    plt.axis('off')\n",
    "    img_np = img.numpy().transpose((1,2,0))\n",
    "    img_valid_rng = np.clip(img_np,0,1)\n",
    "    plt.imshow(img_valid_rng)\n",
    "    plt.suptitle('Images')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9ebaf-c0f1-4974-8802-3ef705bc6cd7",
   "metadata": {},
   "source": [
    "### Create DataLoaders for Training, Testing, and Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1bc5f-66f7-422a-8462-f9780e78552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "trn_loader = DataLoader(trn_ds, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# Load testing images\n",
    "tst_loader = DataLoader(tst_ds, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# Load validation images\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be51c0e5-b9a4-44b7-acdd-a871e98ee75f",
   "metadata": {},
   "source": [
    "**Print Shape of Training and Validation DataSets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d03ee3-6bb5-4c5f-ba6c-37c4f87972e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in {'Training Data': trn_loader, 'Validation Data': val_loader}.items():\n",
    "    for X, y in value:\n",
    "        print(f'{key}:')\n",
    "        print(f'Shape of X: {X.shape}')\n",
    "        print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd9f94-d566-4f47-8684-c0d1c001840e",
   "metadata": {},
   "source": [
    "### Initialize CNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d38e48-185b-4e68-b30a-1654472e8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'shape_in': (3, 256, 246),\n",
    "                'initial_filters': 8,\n",
    "                #'num_fc1': 100,\n",
    "                'num_fc1': 12544,\n",
    "                'dropout_rate': 0.25,\n",
    "                'num_classes': num_classes}\n",
    "\n",
    "model_cnn = cnn_tumor(model_params)\n",
    "model = model_cnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd4c92-b526-4759-81bc-d70492bab455",
   "metadata": {},
   "source": [
    "### Summarize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509d15d-db6a-47a3-962b-7b7ade523b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_cnn, input_size = (3, 256, 256), device = device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e4a0b-c3b3-4fcd-be6d-f335aa4ec2ab",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer\n",
    "According to <u>*pyTorch*</u> documentation, using `nn.NLLLoss(reduction='sum')` should configure cross entropy loss or *logloss* as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5eca4-f1da-4dff-ac84-2aeb39316a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure loss function\n",
    "loss_func = nn.NLLLoss(reduction='sum')\n",
    "\n",
    "# Define optimizer\n",
    "opt = optim.Adam(model_cnn.parameters(), lr = 0.0003)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode = 'min', factor = 0.5, patience = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75ba8f5-bd77-4c5d-8c21-15246c4eecf5",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333e451-4b44-4b70-899f-5c0db29cad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model training parameters\n",
    "trn_params = {\n",
    "    'train': trn_loader, 'val': val_loader,\n",
    "    'epochs': 100,\n",
    "    'optimizer': opt,\n",
    "    'lr_change': ReduceLROnPlateau(opt, mode = 'min', factor = 0.5, patience = 20,\n",
    "                                   verbose=0),\n",
    "    'f_loss': loss_func,\n",
    "    'weight_path': 'weights.pt',\n",
    "}\n",
    "\n",
    "# Train and Validate Model\n",
    "model_cnn, loss_hist, metric_hist = train_val(model_cnn, trn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c7bfc2-ef96-4962-b1ff-83c5b6c3150b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
