{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a5c87-7904-44bc-88ce-5fa377a654b7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "- Wiley Winters\n",
    "- MSDS 686 Deep Learning\n",
    "- Week 7-8 Kaggle Project&nbsp;&mdash;&nbsp;Brain Tumor Classification\n",
    "- 2025-MAR-\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05873db-0aad-476d-8b41-bd62b38fbe2c",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b5d5-8ee4-487d-b812-9e651e8f0411",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "### Required for 80%\n",
    "Complete project on *kaggle.com* using the skills learned in the <u>Deep Learning</u> class.  The following are required:\n",
    "- Show/plot sample images or data with labels\n",
    "- Include at least on of the following\n",
    "  - Convolution\n",
    "  - Max Pooling\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  - LSTM\n",
    "  - TF-IDf\n",
    "- Use validation data\n",
    "- Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333805a-2b73-4173-89af-5e8f15c229dc",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "### Additional for another 20%\n",
    "- Use data augmentation\n",
    "- Use at least one of the following:\n",
    "  - Kernels\n",
    "  - Activation functions\n",
    "  - Loss functions\n",
    "  - Libraries\n",
    "  - Methods\n",
    "- Learning rate optimization\n",
    "- Functional API model\n",
    "- Transfer learning with or without trainable parameters\n",
    "- Confusion matrix and / or ROC plots\n",
    "- Plots of accuracy/loss vs epochs\n",
    "- Show/plot sample incorrect prediction with labels and correct label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ff122-b739-4898-b7c2-7da8051f4c91",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "## Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b571d24-526c-4b90-84b1-d1f484d67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import os, logging, random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# openCV2 image manipulation library\n",
    "import cv2 as cv\n",
    "\n",
    "# TensorFlow likes to display a lot of debug information\n",
    "# on my home system\n",
    "# I will squash the messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorFlow').setLevel(logging.FATAL)\n",
    "\n",
    "# Tensorflow and keras APIs for convoluted neural Networks (CNN)s\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import Xception\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# Make plots have guidelines\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Squash Python warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb16e6f-e27c-4e62-a1e0-e45be18f5204",
   "metadata": {},
   "source": [
    "### Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbe0b5-e813-4917-aadc-06cad648d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703e0d1-2a4c-40f9-ad69-f8f1a52eaef1",
   "metadata": {},
   "source": [
    "### Declare Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498fd7-d5d9-4bce-a59a-8745b6ce98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing image directories\n",
    "home_dir = '/home/wiley'\n",
    "trn_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/training'\n",
    "tst_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/testing'\n",
    "\n",
    "#home_dir = '/disk01/e384698'\n",
    "#trn_dir = home_dir+'/msds686/week7/images/data/training'\n",
    "#tst_dir = home_dir+'/msds686/week7/images/data/testing'\n",
    "\n",
    "# Define classes\n",
    "labels = ['negative', 'positive']\n",
    "\n",
    "# Define early_stop callback\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "# Image size and shape\n",
    "img_size = (224, 224)\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08646792-0d91-4220-8db5-5e36ff566c52",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8c290-901c-4305-9ba9-e09ceed6d848",
   "metadata": {},
   "source": [
    "### Load DataFrames\n",
    "- Join image filename with path information\n",
    "- Create labels from class directory names\n",
    "- Create dataframe\n",
    "- Randomize dataframe rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139e6d0-1db9-4cd3-a15a-5329c085dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(path):\n",
    "    labels, paths = zip(*[(label, os.path.join(path, label, image))\n",
    "                        for label in os.listdir(path)\n",
    "                        if os.path.isdir(os.path.join(path, label))\n",
    "                        for image in os.listdir(os.path.join(path, label))])\n",
    "\n",
    "    df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fcc351-1518-4743-a480-9b4cee25b847",
   "metadata": {},
   "source": [
    "### Load Data and Perform Image Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de99042-fc1b-411d-a46a-a965a3cfe84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data and resize images\n",
    "def load_data(data_path, labels, img_size=224):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for label in labels:\n",
    "        label_path = os.path.join(data_path, label)\n",
    "        for img_name in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "            img = cv.imread(img_path)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            img = cv.resize(img, (img_size, img_size))\n",
    "            X.append(img)\n",
    "            y.append(labels.index(label))\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4de778-8eb8-4f64-801a-c45644cdc068",
   "metadata": {},
   "source": [
    "### Plot Performance Metrics\n",
    "Plot the following:\n",
    "- Training loss\n",
    "- Validation loss\n",
    "- Training Precision\n",
    "- Validation Precision\n",
    "- Training Recall\n",
    "- Validation Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824ec9-23e7-495a-9895-7321b8861f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance Metrics\n",
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(epochs, history.history['precision'], 'b', label='Training Precision')\n",
    "    plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "    plt.title('Training and Validation Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(epochs, history.history['recall'], 'b', label='Training Recall')\n",
    "    plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "    plt.title('Training and Validation Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle('Model Training Metrics over Epochs', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b5bd9-cb71-48e1-9844-c4aaef85bd14",
   "metadata": {},
   "source": [
    "### Display Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6fc6e-06ff-4cc2-a3ea-02c676339139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(path):\n",
    "    num_images=5\n",
    "    image_filenames = os.listdir(path)\n",
    "    num_images = min(num_images, len(image_filenames))\n",
    "    sample = random.sample(image_filenames, num_images)\n",
    "    fig, ax = plt.subplots(1, num_images, figsize=(15,3), facecolor='grey')\n",
    "\n",
    "    for i, image_filename in enumerate(sample[:num_images]):\n",
    "        image_path = os.path.join(path, image_filename)\n",
    "        image = mpimg.imread(image_path)\n",
    "\n",
    "        ax[i].imshow(image)\n",
    "        ax[i].axis('off')\n",
    "        ax[i].set_title(image_filename)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f5077-8110-4427-a711-4fa3a457d08e",
   "metadata": {},
   "source": [
    "### Score Model's Performance on Test Data\n",
    "Will measure model performance on the following scores:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577b362-86a3-4dd5-8135-5675545b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results from test data\n",
    "def model_evaluate(model, ds):\n",
    "    score = model.evaluate(ds)\n",
    "    print('-' * 30)\n",
    "    print('\\033[1m'+'Test results:'+'\\033[0m')\n",
    "    print(f'Test Accuracy Score: {score[0]:.4f}')\n",
    "    print('-' * 30)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e51bf-ce68-418a-95d9-e2bd061af0e5",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "I will initially load the image paths and labels into panda DataFrames for EDA and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68e32f-2bd3-45c4-a391-2830c3d44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training image information into a dataframe\n",
    "trn_df = load_dataframe(trn_dir)\n",
    "\n",
    "# Load testing image information into a dataframe\n",
    "tst_df = load_dataframe(tst_dir)\n",
    "\n",
    "# Take a look at the results\n",
    "print('-->Training DataFrame:\\n', trn_df.head(10).to_markdown())\n",
    "print('-->Testing DataFrame:\\n', tst_df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9db2-c2c8-47bd-b7e8-f8e560893cbb",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2877-8ac2-4ec1-9538-058148afa3b4",
   "metadata": {},
   "source": [
    "### Look at Training Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfd0c-6a4f-467f-b2db-9660ef784211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "trn_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83417025-01e6-4455-8da6-4b296105fd5b",
   "metadata": {},
   "source": [
    "Classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58827-788f-4a7f-b3cc-d3e1c5b1794c",
   "metadata": {},
   "source": [
    "### Look at Testing Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721c78-2fe1-4ead-9893-719aa5358cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "tst_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Testing Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45b538-95f6-4941-b788-911279995810",
   "metadata": {},
   "source": [
    "Distribution mirrors what the *training data* shows, but with less frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ff1b3-260f-4859-be30-6331e3b90cf5",
   "metadata": {},
   "source": [
    "<b><span style='color:red'>NOTE:</span></b>&nbsp;Classes are imbalance and may cause the model to favor the majority class over the minority one. This will have to be handled.  Some options include:\n",
    "- Use a different evaluate metric such as **F1 Score**\n",
    "- Resampling such as over or under sampling\n",
    "- For image data I can use augmentation to attempt to balance the classes\n",
    "- Tell model to give more weight to the minority class through a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9268e-735f-4c8f-8eda-b90d7766f17a",
   "metadata": {},
   "source": [
    "### Examine Shape of Training and Testing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbc83e-c39f-4fa3-be99-77ce26ea9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Shape:\\n', trn_df.shape)\n",
    "print('Testing Shape:\\n', tst_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8aa5-b7de-4a72-9fcc-7621af79763f",
   "metadata": {},
   "source": [
    "<b><span style='color:red'>NOTE:</span></b>&nbsp;Since the dataframes are built from the contents of the image directories, there should be no missing values or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592be8b7-7645-4c17-b02f-736c0dc560d7",
   "metadata": {},
   "source": [
    "### View a Few Images\n",
    "<b><span style='color:orange'>TO DO</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08465dc-a66c-4da1-bc69-960a211e70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_images(trn_dir+'/positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e147d77-1ae2-418c-9d9a-943c6529ebc0",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952598-74ad-4b34-ac38-6f1738915fff",
   "metadata": {},
   "source": [
    "### Load Image and Label information into tensors\n",
    "I will use the standard *X_train*, *X_test*, *y_train*, and *y_test* for the variable names.  I see this convention quite often when researching AI/ML topics and it was presented this way in ***MSDS 680 Machine Learning***.  This maps out to the following:\n",
    "- X_train&nbsp;&mdash;&nbsp;Training Data\n",
    "- y_train&nbsp;&mdash;&nbsp;Training Labels\n",
    "- X_test&nbsp;&mdash;&nbsp;Testing Data\n",
    "- y_test&nbsp;&mdash;&nbsp;Testing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b32df-808b-4c56-a8d9-40b36d7dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into np arrays and standardize image size and color depth\n",
    "X_train, y_train = load_data(trn_dir, labels)\n",
    "X_test, y_test = load_data(tst_dir, labels)\n",
    "\n",
    "# Normalize pixel data\n",
    "X_train, X_test = X_train.astype('float32') / 255.0, X_test.astype('float32') / 255.0\n",
    "\n",
    "# Apply one-hot encodeing to labels\n",
    "y_train, y_test = to_categorical(y_train, num_classes), to_categorical(y_test, num_classes)\n",
    "\n",
    "# Subset validation data from training dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc025d-8441-4cec-9ff9-24066ace5f5b",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "The number of images in this dataset is relatively small; therefore, I will apply image augmentation to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcfb10-2317-4e1b-964a-0a1888323229",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      brightness_range=(0.5, 1.5))\n",
    "\n",
    "# Only have to apply augmentation to training data\n",
    "gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c5b4f-ca6e-41d6-9923-ea713edb387e",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "This model is a Convolutional Neural Network (CNN) designed to classify images into two categories (*negative* or *positive*).  It consists of three convolution layers separated by pooling.  After the convolution layers perform their tasks, the results are passed to two dense layers for final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec8ba1-94e8-4796-ba7a-d2c69fcaadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "backend.clear_session()\n",
    "\n",
    "inputs  = Input(shape=(img_shape))\n",
    "\n",
    "# Conv Layer 1\n",
    "conv1   = Conv2D(filters=28, kernel_size=5, padding='same',\n",
    "                 activation='relu')(inputs)\n",
    "pool1   = MaxPool2D()(conv1)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv2   = Conv2D(filters=56, kernel_size=5, padding='same',\n",
    "                 activation='relu')(pool1)\n",
    "pool2   = MaxPool2D()(conv2)\n",
    "\n",
    "# Conv Layer 3\n",
    "conv3   = Conv2D(filters=128, kernel_size=5, padding='same',\n",
    "                 activation='relu')(pool2)\n",
    "pool3   = MaxPool2D()(conv3)\n",
    "\n",
    "# Apply Batch Normalization, Flatten, and Dense Layers\n",
    "batch3  = BatchNormalization()(pool3)\n",
    "flatten = Flatten()(batch3)\n",
    "dense   = Dense(128, activation='relu')(flatten)\n",
    "dropout = Dropout(0,5)(dense)\n",
    "dense1   = Dense(512, activation='relu')(dropout)\n",
    "\n",
    "# Pull the model together\n",
    "preds   = Dense(num_classes, activation='softmax')(dense1)\n",
    "\n",
    "model_base = Model(inputs, preds)\n",
    "\n",
    "# Compile base model\n",
    "model_base.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Print summary of model\n",
    "model_base.summary()\n",
    "\n",
    "# Plot model\n",
    "plot_model(model_base, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ff2eb-7272-4ae7-a4e0-58dc547d4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training and validation datasets from tensors\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(8)\n",
    "\n",
    "# Fit datasets to model\n",
    "hist_base = model_base.fit(train_ds, epochs=50, batch_size=128,\n",
    "                           validation_data=val_ds,\n",
    "                           callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f214d-a14a-4c7c-a757-81e9ff922ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "plot_history(hist_base)\n",
    "\n",
    "# Evaluate test data\n",
    "#model_evaluate(model_base, tst_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8446dd-bc2a-4c79-ac83-2eb5337417c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_base.evaluate(X_test, y_test)\n",
    "print('-->Test Loss:     ', test_loss)\n",
    "print('-->Test Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63659c3d-765a-4d7f-85e8-68e8024f8238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
