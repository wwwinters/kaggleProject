{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a5c87-7904-44bc-88ce-5fa377a654b7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "- Wiley Winters\n",
    "- MSDS 686 Deep Learning\n",
    "- Week 7-8 Kaggle Project&nbsp;&mdash;&nbsp;Brain Tumor Classification\n",
    "- 2025-MAR-\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05873db-0aad-476d-8b41-bd62b38fbe2c",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b5d5-8ee4-487d-b812-9e651e8f0411",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "### Required for 80%\n",
    "Complete project on *kaggle.com* using the skills learned in the <u>Deep Learning</u> class.  The following are required:\n",
    "- Show/plot sample images or data with labels\n",
    "- Include at least on of the following\n",
    "  - Convolution\n",
    "  - Max Pooling\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  - LSTM\n",
    "  - TF-IDf\n",
    "- Use validation data\n",
    "- Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333805a-2b73-4173-89af-5e8f15c229dc",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "### Additional for another 20%\n",
    "- Use data augmentation\n",
    "- Use at least one of the following:\n",
    "  - Kernels\n",
    "  - Activation functions\n",
    "  - Loss functions\n",
    "  - Libraries\n",
    "  - Methods\n",
    "- Learning rate optimization\n",
    "- Functional API model\n",
    "- Transfer learning with or without trainable parameters\n",
    "- Confusion matrix and / or ROC plots\n",
    "- Plots of accuracy/loss vs epochs\n",
    "- Show/plot sample incorrect prediction with labels and correct label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ff122-b739-4898-b7c2-7da8051f4c91",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "## Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b571d24-526c-4b90-84b1-d1f484d67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, logging, random\n",
    "\n",
    "# Data prep and model scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# TensorFlow likes to display a lot of debug information\n",
    "# on my home system\n",
    "# I will squash the messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorFlow').setLevel(logging.FATAL)\n",
    "\n",
    "# tensorflow and keras' API\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Model building\n",
    "from keras.applications import Xception\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Model architecture visualization\n",
    "from visualkeras import layered_view\n",
    "\n",
    "# Model training\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Make plots have guidelines\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Squash Python warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb16e6f-e27c-4e62-a1e0-e45be18f5204",
   "metadata": {},
   "source": [
    "### Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbe0b5-e813-4917-aadc-06cad648d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703e0d1-2a4c-40f9-ad69-f8f1a52eaef1",
   "metadata": {},
   "source": [
    "### Declare Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498fd7-d5d9-4bce-a59a-8745b6ce98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing image directories\n",
    "home_dir = '/home/wiley'\n",
    "trn_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/training'\n",
    "tst_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/testing'\n",
    "\n",
    "#home_dir = '/disk01/e384698'\n",
    "#trn_dir = home_dir+'/msds686/week7/images/data/training/'\n",
    "#tst_dir = home_dir+'/msds686/week7/images/data/testing/'\n",
    "\n",
    "# Define classes\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "# Define early_stop callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-9, patience=8,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "# Define reduce LR on Plateau callback\n",
    "reduceLRO = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5,\n",
    "                              min_delta=0.0001, min_lr=0,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "# Image size and shape\n",
    "img_size = (224, 224)\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08646792-0d91-4220-8db5-5e36ff566c52",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd99b9d-667a-4d32-943f-208ca067051a",
   "metadata": {},
   "source": [
    "### Load DataFrames\n",
    "- Join image filename and path information\n",
    "- Create labels from class directory names\n",
    "- Create dataframe\n",
    "- Randomize dataframe rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215f093-56a5-45bb-acb2-52319ee78c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(path):\n",
    "    labels, paths = zip(*[(label, os.path.join(path, label, image))\n",
    "                        for label in os.listdir(path)\n",
    "                        if os.path.isdir(os.path.join(path, label))\n",
    "                        for image in os.listdir(os.path.join(path, label))])\n",
    "\n",
    "    df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e05eb6-e0e3-417c-b54f-3addb925c7c0",
   "metadata": {},
   "source": [
    "### Plot Performance Metrics\n",
    "Plot the following:\n",
    "- Training loss\n",
    "- Validation loss\n",
    "- Training Precision\n",
    "- Validation Precision\n",
    "- Training Recall\n",
    "- Validation Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824ec9-23e7-495a-9895-7321b8861f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation precision\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(epochs, history.history['precision'], 'b', label='Training Precision')\n",
    "    plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "    plt.title('Training and Validation Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation recall\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(epochs, history.history['recall'], 'b', label='Training Recall')\n",
    "    plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "    plt.title('Training and Validation Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle('Model Training Metrics over Epochs', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation AUPRC\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(epochs, history.history['auprc'], 'b', label='Training AUPRC')\n",
    "    plt.plot(epochs, history.history['val_auprc'], 'r', label='Validation AUPRC')\n",
    "    plt.title('Training and Validation AUPRC')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('AUPRC')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51eb63e-fdba-4eb9-9bf6-7f81d6908e52",
   "metadata": {},
   "source": [
    "### Evaluate Model's Performance on Test Data\n",
    "- Compute accuracy and loss\n",
    "- Compute AUPRC (**A**rea **U**under the **P**recision&nbsp;&mdash;&nbsp;**R**ecall score)\n",
    "- Compute ROC AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ae6f1-8c57-474a-ac1c-073f30749397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, trn_ds, tst_ds):\n",
    "    my_model = model\n",
    "    prediction = my_model.predict(tst_ds)\n",
    "    train_score = my_model.score(trn_ds)\n",
    "    accur_score = accuracy_score(tst_ds, prediction)\n",
    "    f1 = f1_score(tst_ds, prediction)\n",
    "    roc_score = roc_auc_score(tst_ds, prediction)\n",
    "    cm = confusion_matrix(tst_ds, prediction).flatten()\n",
    "    \n",
    "    print(f'Model:          {my_model}')\n",
    "    print(f'Train Score:    {train_score}')\n",
    "    print(f'Accuracy Score: {accur_score}')\n",
    "    print(f'F1 score:       {f1}')\n",
    "    print(f'ROC AUC Score:  {roc_score}')\n",
    "    print(f'Confusion:      {cm}')\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e51bf-ce68-418a-95d9-e2bd061af0e5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e358d5a-b761-42f9-b74d-26e80b587f7d",
   "metadata": {},
   "source": [
    "### Create and Load DataFrame for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68e32f-2bd3-45c4-a391-2830c3d44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "trn_df = load_dataframe(trn_dir)\n",
    "\n",
    "# Load testing data\n",
    "tst_df = load_dataframe(tst_dir)\n",
    "\n",
    "# Take a look at the results\n",
    "print('Training:   \\n', trn_df.head(10).to_markdown())\n",
    "print('Testing:    \\n', tst_df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9db2-c2c8-47bd-b7e8-f8e560893cbb",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2877-8ac2-4ec1-9538-058148afa3b4",
   "metadata": {},
   "source": [
    "### Look at Training Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfd0c-6a4f-467f-b2db-9660ef784211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "trn_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83417025-01e6-4455-8da6-4b296105fd5b",
   "metadata": {},
   "source": [
    "Positive images slightly outnumber the negative ones, but are close enough to continue without additional data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58827-788f-4a7f-b3cc-d3e1c5b1794c",
   "metadata": {},
   "source": [
    "### Look at Testing Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721c78-2fe1-4ead-9893-719aa5358cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "tst_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Testing Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45b538-95f6-4941-b788-911279995810",
   "metadata": {},
   "source": [
    "Distribution mirrors what the *training data* shows, but with less frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9268e-735f-4c8f-8eda-b90d7766f17a",
   "metadata": {},
   "source": [
    "### Examine Shape of Training and Testing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbc83e-c39f-4fa3-be99-77ce26ea9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Shape: \\n', trn_df.shape)\n",
    "print('Testing Shape:  \\n', tst_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8aa5-b7de-4a72-9fcc-7621af79763f",
   "metadata": {},
   "source": [
    "**NOTE:**&nbsp;&nbsp;Since the dataframes are built from the contents of the image directories, there should be no missing values or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e147d77-1ae2-418c-9d9a-943c6529ebc0",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ca6dd-a6b7-4bbb-b493-65a39e414d94",
   "metadata": {},
   "source": [
    "### Create a Validation Subset from Training Data\n",
    "I will use `flow_from_dataframe()` to create datasets for model training; therefore, no reason to create a new directory structure for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f94b2-2e1b-4764-b361-56a1372ae55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, trn_df = train_test_split(trn_df, train_size=0.2, random_state=42,\n",
    "                                  stratify=trn_df['labels'])\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952598-74ad-4b34-ac38-6f1738915fff",
   "metadata": {},
   "source": [
    "## Process Images from DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b32df-808b-4c56-a8d9-40b36d7dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "\n",
    "gen = ImageDataGenerator(brightness_range=(0.5, 1.5),\n",
    "                         rotation_range=20,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2)\n",
    "\n",
    "tst_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trn_gen = gen.flow_from_dataframe(trn_df, x_col='paths', y_col='labels',\n",
    "                                  batch_size=bs, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "val_gen = gen.flow_from_dataframe(val_df, x_col='paths', y_col='labels',\n",
    "                                  batch_size=bs, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "tst_gen = tst_gen.flow_from_dataframe(tst_df, x_col='paths', y_col='labels',\n",
    "                                      batch_size=16, target_size=img_size,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8276ee3-e00a-476c-b651-da13679a6b9d",
   "metadata": {},
   "source": [
    "## Examine a few Images and their Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbac09-495d-47f5-9ec3-3f4b6cd79282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = trn_gen.class_indices\n",
    "classes = list(dict.keys())\n",
    "images, labels = next(tst_gen)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(image)\n",
    "    class_name = classes[np.argmax(label)]\n",
    "    plt.title(class_name, color='k', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e98e7-2fbf-4d83-8354-0db82190a310",
   "metadata": {},
   "source": [
    "### Configure Training Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8a1dc-5efd-4236-a7a4-3a3fba2af358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 50\n",
    "\n",
    "# Steps per epoch\n",
    "steps_per_ep = trn_gen.samples // batch_size\n",
    "\n",
    "# Validation steps\n",
    "val_steps = tst_gen.samples // batch_size\n",
    "\n",
    "print(f'Image shape:      {img_shape}')\n",
    "print(f'Epochs:           {epochs}')\n",
    "print(f'Batch size:       {batch_size}')\n",
    "print(f'Steps per epoch:  {steps_per_ep}')\n",
    "print(f'Validation steps: {val_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c5b4f-ca6e-41d6-9923-ea713edb387e",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "### Define Model's Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ad99-4702-454c-8623-7fea704edcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "inputs  = Input(shape=(img_shape))\n",
    "\n",
    "# Conv Layer 1\n",
    "conv1   = Conv2D(filters=32, kernel_size=4, padding='same',\n",
    "                 activation='relu')(inputs)\n",
    "pool1   = MaxPooling2D()(conv1)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv2   = Conv2D(filters=64, kernel_size=4, padding='same',\n",
    "                 activation='relu')(pool1)\n",
    "pool2   = MaxPooling2D()(conv2)\n",
    "\n",
    "# Conv Layer 3\n",
    "conv3   = Conv2D(filters=128, kernel_size=4, padding='same',\n",
    "                 activation='relu')(pool2)\n",
    "pool3   = MaxPooling2D()(conv3)\n",
    "\n",
    "# Apply Batch Normalization, Flatten, and Dense Layers\n",
    "batch3  = BatchNormalization()(pool3)\n",
    "flatten = Flatten()(batch3)\n",
    "dense1   = Dense(128, activation='relu')(flatten)\n",
    "dropout = Dropout(0,5)(dense1)\n",
    "dense2   = Dense(512, activation='relu')(dropout)\n",
    "\n",
    "# Pull the model together\n",
    "preds   = Dense(num_classes, activation='softmax')(dense1)\n",
    "\n",
    "model_base = Model(inputs, preds)\n",
    "\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636cf49-9a31-4567-848c-b09fd9158220",
   "metadata": {},
   "source": [
    "### Visualize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24608a69-a7c0-49ad-a8f9-262ceff7e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layered_view(model_base, legend=True, max_xy=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c278a-18fd-4b0d-8793-467dbb8d8cf2",
   "metadata": {},
   "source": [
    "### Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd440b9-60ac-4935-abcf-c0f89d8de63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile base model\n",
    "model_base.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy', Precision(), Recall(),\n",
    "                            tf.keras.metrics.AUC(curve='PR', name='auprc')])\n",
    "\n",
    "hist_base = model_base.fit(trn_gen, steps_per_epoch=steps_per_ep, epochs=epochs,\n",
    "                           validation_data=val_gen,\n",
    "                           validation_steps=val_steps,\n",
    "                           callbacks=[early_stop, reduceLRO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24589b86-f6fd-4b4b-bf69-470cee3e1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64842a5-ceca-4299-9fa7-1fb300ad930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(hist_base.history)\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4d29e-3f9e-4831-b75a-9e9bda54c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.evaluate(tst_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7451bdf-e6a4-44b1-8e7f-39886ad6f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "trn_pred = np.argmax(np.round(model_base.predict(trn_gen)), axis=1)\n",
    "tst_pred = np.argmax(np.round(model_base.predict(tst_gen)), axis=1)\n",
    "\n",
    "# Produce confusion matrix\n",
    "trn_cm = confusion_matrix(trn_gen.classes, trn_pred)\n",
    "tst_cm = confusion_matrix(tst_gen.classes, tst_pred)\n",
    "\n",
    "print(f'Training Confusion Matrix:\\n {trn_cm}')\n",
    "print(f'Testing Confusion Matrix:\\n {tst_cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c54ea5-9e69-4cce-8c13-f2ba7b4ab992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
