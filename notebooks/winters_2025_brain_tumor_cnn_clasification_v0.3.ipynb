{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a5c87-7904-44bc-88ce-5fa377a654b7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "- Wiley Winters\n",
    "- MSDS 686 Deep Learning\n",
    "- Week 7-8 Kaggle Project&nbsp;&mdash;&nbsp;Brain Tumor Classification\n",
    "- 2025-MAR-09\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05873db-0aad-476d-8b41-bd62b38fbe2c",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b5d5-8ee4-487d-b812-9e651e8f0411",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "### Required for 80%\n",
    "Complete project on *kaggle.com* using the skills learned in the <u>Deep Learning</u> class.  The following are required:\n",
    "- Show/plot sample images or data with labels\n",
    "- Include at least one of the following\n",
    "  - Convolution\n",
    "  - Max Pooling\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  - LSTM\n",
    "  - TF-IDf\n",
    "- Use validation data\n",
    "- Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333805a-2b73-4173-89af-5e8f15c229dc",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "## Additional for another 20%\n",
    "- Use data augmentation\n",
    "- Use at least one of the following:\n",
    "  - Kernels\n",
    "  - Activation functions\n",
    "  - Loss functions\n",
    "  - Libraries\n",
    "  - Methods\n",
    "- Learning rate optimization\n",
    "- Functional API model\n",
    "- Transfer learning with or without trainable parameters\n",
    "- Confusion matrix and / or ROC plots\n",
    "- Plots of accuracy/loss vs epochs\n",
    "- Show/plot sample incorrect prediction with labels and correct label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ff122-b739-4898-b7c2-7da8051f4c91",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "<a name='imports'></a>\n",
    "## 1.0 <span style='color:blue'>|</span> Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b571d24-526c-4b90-84b1-d1f484d67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, logging, random\n",
    "from datetime import datetime\n",
    "\n",
    "# Data prep and model scoring\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# TensorFlow likes to display a lot of debug information\n",
    "# on my home system\n",
    "# I will squash the messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorFlow').setLevel(logging.FATAL)\n",
    "\n",
    "# tensorflow and keras' API\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Model building\n",
    "from tensorflow.keras import backend, optimizers, regularizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Model architecture visualization\n",
    "from visualkeras import layered_view\n",
    "\n",
    "# Model training\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "# Make plots have guidelines\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Squash Python warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb16e6f-e27c-4e62-a1e0-e45be18f5204",
   "metadata": {},
   "source": [
    "<a name='random'></a>\n",
    "### 1.1 <span style='color:blue'>|</span> Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbe0b5-e813-4917-aadc-06cad648d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703e0d1-2a4c-40f9-ad69-f8f1a52eaef1",
   "metadata": {},
   "source": [
    "<a name='global'></a>\n",
    "### 1.2 <span style='color:blue'>|</span> Declare Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498fd7-d5d9-4bce-a59a-8745b6ce98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing image directories\n",
    "home_dir = '/home/wiley'\n",
    "trn_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/training'\n",
    "tst_dir = home_dir+'/regis/dataScience/kaggleProject/images/data/testing'\n",
    "\n",
    "# Define classes\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "# Image size and shape\n",
    "img_size = (224, 224)\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Declare batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Flag to save weights\n",
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08646792-0d91-4220-8db5-5e36ff566c52",
   "metadata": {},
   "source": [
    "<a name='functions'></a>\n",
    "## 2.0 <span style='color:blue'>|</span> Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd99b9d-667a-4d32-943f-208ca067051a",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    "<a name='load_df'></a>\n",
    "### 2.1 <span style='color:blue'>|</span> Load DataFrames\n",
    "- Join image filename and path information\n",
    "- Create labels from class directory names\n",
    "- Create dataframe\n",
    "- Randomize dataframe rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215f093-56a5-45bb-acb2-52319ee78c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(path):\n",
    "    # Derive image file paths and labels from directory structure\n",
    "    labels, paths = zip(*[(label, os.path.join(path, label, image))\n",
    "                        for label in os.listdir(path)\n",
    "                        if os.path.isdir(os.path.join(path, label))\n",
    "                        for image in os.listdir(os.path.join(path, label))])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'paths': paths, 'labels': labels})\n",
    "    \n",
    "    # Randomize rows to help eliminate bias\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e05eb6-e0e3-417c-b54f-3addb925c7c0",
   "metadata": {},
   "source": [
    "<a name='metrics'></a>\n",
    "### 2.2 <span style='color:blue'>|</span> Plot Performance Metrics\n",
    "Plot the following:\n",
    "- Training loss\n",
    "- Validation loss\n",
    "- Training Accuracy\n",
    "- Validation Accuracy\n",
    "- Training Precision\n",
    "- Validation Precision\n",
    "- Training Recall\n",
    "- Validation Recall\n",
    "- Training AUC\n",
    "- Validation AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824ec9-23e7-495a-9895-7321b8861f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle('Model Loss and Accuracy over Epochs', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation precision\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['precision'], 'b', label='Training Precision')\n",
    "    plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "    plt.title('Training and Validation Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation recall\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['recall'], 'b', label='Training Recall')\n",
    "    plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "    plt.title('Training and Validation Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle('Model Precision and Recall over Epochs', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation AUC\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(epochs, history.history['auc'], 'b', label='Training AUC')\n",
    "    plt.plot(epochs, history.history['val_auc'], 'r', label='Validation AUC')\n",
    "    plt.title('Training and Validation AUC')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51eb63e-fdba-4eb9-9bf6-7f81d6908e52",
   "metadata": {},
   "source": [
    "<a name='performance'></a>\n",
    "### 2.3 <span style='color:blue'>|</span> Evaluate Model's Performance on Test DataSet\n",
    "- Infer loss, accuracy, precision, recall, and AUC from dataset\n",
    "- Compute F1 Score from precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084c019-8ba9-4c46-a443-b619edb6ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, ds):\n",
    "    # Get metrics from test data\n",
    "    loss, acc, auc, prec, recall = model.evaluate(ds)\n",
    "\n",
    "    # Calculate F1 Score from precision and recall\n",
    "    f1_score = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "    # Print results\n",
    "    print('-' * 30)\n",
    "    print(f'Loss:      {loss:.4f}')\n",
    "    print(f'Accuracy:  {acc:.4f}')\n",
    "    print(f'Precision:  {prec:.4f}')\n",
    "    print(f'Recall:    {recall:.4f}')\n",
    "    print(f'AUC:       {auc:.4f}')\n",
    "    print(f'F1 Score:  {f1_score:.4f}')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197583d0-9795-48c5-a8f4-47ba3cf21d70",
   "metadata": {},
   "source": [
    "<a name='cm_matrix'></a>\n",
    "### 2.4 <span style='color:blue'>|</span> Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e2ab2-643d-4d87-8ffe-7b3c1f60f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(model, ds):\n",
    "    # Get predictions from dataset\n",
    "    preds = np.argmax(np.round(model.predict(ds)), axis=1)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(ds.classes, preds)\n",
    "\n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='viridis',\n",
    "                xticklabels=classes,\n",
    "                yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de302e02-3f44-44d8-a5e9-2c42ca0bf1cc",
   "metadata": {},
   "source": [
    "<a name='tpr'></a>\n",
    "### 2.5 <span style='color:blue'>|</span> Compute TPR and TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09938361-5164-46cf-8dcd-66150a3bf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tpr(model, ds):\n",
    "    # get predictions from dataset\n",
    "    preds = np.argmax(np.round(model.predict(ds)), axis=1)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(ds.classes, preds)\n",
    "\n",
    "    # Extract required values from confusion matrix\n",
    "    (tn, fp, fn, tp) = cm.flatten()\n",
    "\n",
    "    # Calculate TPR\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calculate TNR\n",
    "    tnr = tn / (tn + fp)\n",
    "\n",
    "    # Print TPR and TNR\n",
    "    print('-' * 30)\n",
    "    print(f'True Positive Rate (TPR): {tpr:.4f}')\n",
    "    print(f'True Negative Rate (TNR): {tnr:.4f}')\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919427f1-114c-4115-bc95-e35a23693e1b",
   "metadata": {},
   "source": [
    "<a name='show_predictions'></a>\n",
    "### 2.6 <span style='color:blue'>|</span> Show True vs Predicted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5e64d-b728-4ff2-9170-45e399ee15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_preds(model, ds):\n",
    "    # Extract true and predicted labels from dataset\n",
    "    images, labels = next(ds)\n",
    "    preds = model.predict(images)\n",
    "    pred_labs = np.argmax(preds, axis=1)\n",
    "    dict = ds.class_indices\n",
    "    tr_labels = list(dict.keys())\n",
    "\n",
    "    # Plot the images with true and predicted labels\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        tr_label = classes[np.argmax(label)]\n",
    "        pred_label = classes[pred_labs[i]]\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(img)\n",
    "        color = 'green' if tr_label == pred_label else 'red'\n",
    "        plt.title('True:      %s \\nPredict:  %s' % (tr_label, pred_label), fontsize=15,\n",
    "                  loc='left', color=color)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b095e-b0f2-4638-b1ea-e02dde4f72e8",
   "metadata": {},
   "source": [
    "<a name='print_imgs'></a>\n",
    "### 2.7 <span style='color:blue'>|</span> Print Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a6d49-ae12-4e92-a9c7-71449741e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(ds):\n",
    "    # Pull images and labels out of the dataset\n",
    "    images, labels = next(ds)\n",
    "\n",
    "    # Create a dictionary of class indices\n",
    "    dict = ds.class_indices\n",
    "\n",
    "    # Form classes from the dictionary created in last step\n",
    "    classes = list(dict.keys())\n",
    "\n",
    "    # Plot the images and labels -- 16 images at a time\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for i in range(16):\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "        class_name = classes[np.argmax(label)]\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name, loc='left', fontsize=15)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e51bf-ce68-418a-95d9-e2bd061af0e5",
   "metadata": {},
   "source": [
    "<a name=load_data></a>\n",
    "## 3.0 <span style='color:blue'>|</span> Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e358d5a-b761-42f9-b74d-26e80b587f7d",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "<a name='load_df'></a>\n",
    "### 3.1 <span style='color:blue'>|</span> Create and Load DataFrame for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68e32f-2bd3-45c4-a391-2830c3d44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "trn_df = load_dataframe(trn_dir)\n",
    "\n",
    "# Load testing data\n",
    "tst_df = load_dataframe(tst_dir)\n",
    "\n",
    "# Take a look at the results\n",
    "print('Training:   \\n', trn_df.head(10).to_markdown())\n",
    "print('Testing:    \\n', tst_df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9db2-c2c8-47bd-b7e8-f8e560893cbb",
   "metadata": {},
   "source": [
    "<a name='eda'></a>\n",
    "## 4.0 <span style='color:blue'>|</span> EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2877-8ac2-4ec1-9538-058148afa3b4",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "<a name='trn_dist'></a>\n",
    "### 4.1 <span style='color:blue'>|</span> Look at Training Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfd0c-6a4f-467f-b2db-9660ef784211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "trn_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83417025-01e6-4455-8da6-4b296105fd5b",
   "metadata": {},
   "source": [
    "Negative images slightly outnumber the positive ones, but are close enough to continue without additional data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58827-788f-4a7f-b3cc-d3e1c5b1794c",
   "metadata": {},
   "source": [
    "<a name='tst_dist'></a>\n",
    "### 4.2 <span style='color:blue'>|</span> Look at Testing Images' Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721c78-2fe1-4ead-9893-719aa5358cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "tst_df['labels'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Testing Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45b538-95f6-4941-b788-911279995810",
   "metadata": {},
   "source": [
    "Distribution mirrors what the *training data* shows, but with less frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9268e-735f-4c8f-8eda-b90d7766f17a",
   "metadata": {},
   "source": [
    "<a name='shape'></a>\n",
    "### 4.3 <span style='color:blue'>|</span> Examine Shape of Training and Testing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbc83e-c39f-4fa3-be99-77ce26ea9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Shape: \\n', trn_df.shape)\n",
    "print('Testing Shape:  \\n', tst_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8aa5-b7de-4a72-9fcc-7621af79763f",
   "metadata": {},
   "source": [
    "**NOTE:**&nbsp;&nbsp;Since the dataframes are built from the contents of the image directories, there should be no missing values or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e147d77-1ae2-418c-9d9a-943c6529ebc0",
   "metadata": {},
   "source": [
    "<a name='wrangling'></a>\n",
    "## 4.0 <span style='color:blue'>|</span> Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ca6dd-a6b7-4bbb-b493-65a39e414d94",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "<a name='cr_val'></a>\n",
    "### 4.1 <span style='color:blue'>|</span> Create a Validation Subset from Training Data\n",
    "I will use `flow_from_dataframe()` to create datasets for model training; therefore, no reason to create a new directory structure for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f94b2-2e1b-4764-b361-56a1372ae55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, trn_df = train_test_split(trn_df, train_size=0.2, random_state=42,\n",
    "                                  stratify=trn_df['labels'])\n",
    "print(val_df.sample(10).to_markdown())\n",
    "print(f'Validation Shape: {val_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952598-74ad-4b34-ac38-6f1738915fff",
   "metadata": {},
   "source": [
    "<a name='proc_imgs'></a>\n",
    "### 4.2 <span style='color:blue'>|</span> Process Images from DataFrames\n",
    "Image augmentation will be used on the training and validation datasets.  The test images will just be normalized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b32df-808b-4c56-a8d9-40b36d7dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image augmentation\n",
    "gen = ImageDataGenerator(rescale=1./255,\n",
    "                         brightness_range=(0.5, 1.5),\n",
    "                         rotation_range=20,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2)\n",
    "\n",
    "# The test dataset should not be augmented\n",
    "# just rescaled\n",
    "tst_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create training datagen set\n",
    "trn_gen = gen.flow_from_dataframe(trn_df, x_col='paths', y_col='labels',\n",
    "                                  batch_size=batch_size, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "# Create validation datagen set\n",
    "val_gen = gen.flow_from_dataframe(val_df, x_col='paths', y_col='labels',\n",
    "                                  batch_size=batch_size, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "# Create test datagen set\n",
    "tst_gen = tst_gen.flow_from_dataframe(tst_df, x_col='paths', y_col='labels',\n",
    "                                      batch_size=16, target_size=img_size,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8276ee3-e00a-476c-b651-da13679a6b9d",
   "metadata": {},
   "source": [
    "<a name='exam_imgs'></a>\n",
    "### 4.3 <span style='color:blue'>|</span> Examine a few Augmented Images and their Labels\n",
    "The images displayed have been augmented in the previous step. The appearance may not be consistent with non-augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbac09-495d-47f5-9ec3-3f4b6cd79282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print augmented images from training dataset\n",
    "print_images(trn_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e98e7-2fbf-4d83-8354-0db82190a310",
   "metadata": {},
   "source": [
    "<a name='configure'></a>\n",
    "## 5.0 <span style='color:blue'>|</span> Configure Training Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c43620-17b2-4e09-ae2e-ca3269d6c27c",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "<a name='basic_values'></a>\n",
    "### 5.1 <span style='color:blue'>|</span> Basic Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8a1dc-5efd-4236-a7a4-3a3fba2af358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "epochs = 50\n",
    "\n",
    "# Steps per epoch\n",
    "steps_per_ep = trn_gen.samples // batch_size\n",
    "\n",
    "# Validation steps\n",
    "val_steps = val_gen.samples // batch_size\n",
    "\n",
    "print(f'Image shape:      {img_shape}')\n",
    "print(f'Epochs:           {epochs}')\n",
    "print(f'Batch size:       {batch_size}')\n",
    "print(f'Steps per epoch:  {steps_per_ep}')\n",
    "print(f'Validation steps: {val_steps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b6217f-fb74-4301-a4d0-f23db810a153",
   "metadata": {},
   "source": [
    "<a name='callbacks'></a>\n",
    "### 5.2 <span style='color:blue'>|</span> Define Callbacks\n",
    "With these *callbacks* the model's training will stop if the training loss stops decreasing (`EarlyStopping()`), and the learning rate will be reduced until the validation loss plateaus (`ReduceLROnPlateau()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab248c-be23-4924-aee0-2cd63b9d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early_stop callback\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.000000001, patience=5,\n",
    "                           baseline=None, restore_best_weights=True, start_from_epoch=0)\n",
    "\n",
    "# Define reduce LR on Plateau callback\n",
    "reduceLRO = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, mode='auto',\n",
    "                              min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c5b4f-ca6e-41d6-9923-ea713edb387e",
   "metadata": {},
   "source": [
    "<a name='baseline_model'></a>\n",
    "## 6.0 <span style='color:blue'>|</span> Baseline Model\n",
    "### Define Model's Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3679f1-8937-4c79-975d-74cc2769a616",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "<a name='architecture'></a>\n",
    "### 6.1 <span style='color:blue'>|</span> Define Model's Architecture\n",
    "The CNN model is being defined by using `models.Sequential()` method.  It consists of four convolution layers flattened into two fully connected layers with dropout.  The output layer will use the *softmax* activation function instead of *relu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69448890-8490-4ee9-991e-85b50ca020c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "model_cnn = models.Sequential([\n",
    "    # Conv layer #1\n",
    "    Conv2D(32, (4,4), activation='relu', input_shape=img_shape),\n",
    "    MaxPooling2D(pool_size=(3,3)),\n",
    "\n",
    "    # Conv layer #2\n",
    "    Conv2D(64, (4,4), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3,3)),\n",
    "\n",
    "    # Conv layer #3\n",
    "    Conv2D(128, (4,4), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(4,4)),\n",
    "\n",
    "    # Conv layer #4\n",
    "    Conv2D(128, (4,4), activation='relu'),\n",
    "    Flatten(),  \n",
    "\n",
    "    # Fully connect layers\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5, seed=42),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636cf49-9a31-4567-848c-b09fd9158220",
   "metadata": {},
   "source": [
    "<a name='layered_view'></a>\n",
    "### 6.2 <span style='color:blue'>|</span> Visualize Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24608a69-a7c0-49ad-a8f9-262ceff7e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layered_view(model_cnn, legend=True, max_xy=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c278a-18fd-4b0d-8793-467dbb8d8cf2",
   "metadata": {},
   "source": [
    "<a name='compile'></a>\n",
    "### 6.3 <span style='color:blue'>|</span> Compile and Train Model\n",
    "The `Adam()` optimizer was selected for this model, since it is well suited to classification problems.  The loss function `categorical_crossentropy()` was also selected for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd440b9-60ac-4935-abcf-c0f89d8de63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Adam optimizer\n",
    "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.869, beta_2=0.995)\n",
    "\n",
    "# Compile base model\n",
    "model_cnn.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(name='precision'),\n",
    "                           tf.keras.metrics.Recall(name='recall'),\n",
    "                           tf.keras.metrics.AUC(curve='PR', name='auc')])\n",
    "\n",
    "# Fit data to model and record training history\n",
    "hist_cnn = model_cnn.fit(trn_gen, batch_size=batch_size, steps_per_epoch=steps_per_ep, \n",
    "                         epochs=epochs, validation_data=val_gen,\n",
    "                         validation_steps=val_steps,\n",
    "                         callbacks=[early_stop, reduceLRO])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffd81e-2f3d-4499-9067-ec5e151023e5",
   "metadata": {},
   "source": [
    "<a name='evaluate'></a>\n",
    "## 7.0 <span style='color:blue'>|</span> Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a57c0b-89fb-4591-8f13-8dbfbeebd92f",
   "metadata": {},
   "source": [
    "------------------------------------------------------------\n",
    "<a name='history'></a>\n",
    "### 7.1 <span style='color:blue'>|</span> Plot Training and Validation Metrics\n",
    "If the training and validation metrics diverge significantly from each other, that can be an indication of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24589b86-f6fd-4b4b-bf69-470cee3e1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a8990-e79e-4a32-a0dc-38338a3fe5a6",
   "metadata": {},
   "source": [
    "<a name='score'></a>\n",
    "### 7.2 <span style='color:blue'>|</span> Score Model\n",
    "To evaluate the model's performance the following matrices will be evaluated against the test dataset:\n",
    "- Model Loss&nbsp;&mdash;&nbsp;gives a nuanced view of model optimization\n",
    "- Model Accuracy&nbsp;&mdash;&nbsp;provides the proportion of all classifications that were correct\n",
    "- Precision&nbsp;&mdash;&nbsp;refers to the number of true positives divided by total number of positive predictions\n",
    "- Recall&nbsp;&mdash;&nbsp;proportion of correct positive classifications\n",
    "- Area Under Curve (AUC)&nbsp;&mdash;&nbsp;represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative\n",
    "- F1 Score&nbsp;&mdash;&nbsp;describes the harmonic mean of the precision and recall of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47a315-a071-4d87-bb2e-7f2f71954199",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(model_cnn, tst_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97560d-e7b9-4803-9f29-05b3e8159315",
   "metadata": {},
   "source": [
    "<a name='plot_cm'></a>\n",
    "### 7.3 <span style='color:blue'>|</span> Plot Confusion Matrix\n",
    "A confusion matrix provides a visual representation of a model's performance when it comes to comparing true positives, false negatives, true negatives, and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c54ea5-9e69-4cce-8c13-f2ba7b4ab992",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(model_cnn, tst_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f7aaa-6cf3-4a9f-9ef2-33fd8505fbec",
   "metadata": {},
   "source": [
    "<a name=tpr_tnr></a>\n",
    "### 7.4 <span style='color:blue'>|</span> Compute TPR and TNR\n",
    "The True Positive Rate (TPR) and True Negative Rate (TNR) are good indicators of how well the model is predicting positives (1s) and negatives (0s).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1171ac-1f91-4cce-a3bd-aa808e0a5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_tpr(model_cnn, tst_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fc6a5-3b9f-4601-a4c9-3f2fa9237554",
   "metadata": {},
   "source": [
    "<a name='view_predictions'></a>\n",
    "### 7.5 <span style='color:blue'>|</span> View and Compare Predicted with True Labels\n",
    "If the ***True*** and ***Predict*** labels match, then the model accurately predicted the label of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b1cbf-2bfd-4830-a0d9-880f7975e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_preds(model_cnn, tst_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a02b35-9b74-4551-b67d-1cec7f56e59b",
   "metadata": {},
   "source": [
    "<a name='save_weights'></a>\n",
    "## 8.0 <span style='color:blue'>|</span> Save Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bbc93-5177-4fe0-a610-bdc5bc9ffde4",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6944592-3364-4a88-9d94-a00c2e495fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use date and time to create a unique filename\n",
    "if save:\n",
    "    now = datetime.now()\n",
    "    date = now.strftime('%Y%m%d')\n",
    "    time = now.strftime('%H%M%S')\n",
    "    filename = date+time+'_cnn_brain_tumor.keras'\n",
    "\n",
    "    # Save weights in keras zip format\n",
    "    model_cnn.save('../weights/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0b769-f4a8-438a-b2a1-749fcb344c91",
   "metadata": {},
   "source": [
    "<a name='discussion'></a>\n",
    "## 9.0 <span style='color:blue'>|</span> Discussion and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902014bb-105c-43ca-9101-fd2502d0d97e",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c179e62-515b-4b00-aa76-c9d4387c8006",
   "metadata": {},
   "source": [
    "\n",
    "<a name='general'></a>\n",
    "### 9.1 <span style='color:blue'>|</span> General Performance\n",
    "The model is generalizing the test data well.  The plots indicated the model is training well and overfitting is minimal.  Training and Validation metrics closely follow each other during the training process and I do not see any items that are concerning.  F1, True Positive, and True Negative scores are above 0.90 which indicates it is accurately predicting positive and negative labels with 90% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17cf99-2c04-4430-a937-26232231740e",
   "metadata": {},
   "source": [
    "<a name='further'></a>\n",
    "### 9.2 <span style='color:blue'>|</span> Further Work\n",
    "While the model is generalizing the test data with acceptable results, it can do better.  I will conduct further research on CNN model tuning and keep experimenting until results are consistently in the high 90s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a51864-572a-4f39-a683-2fdfd9e2f625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
