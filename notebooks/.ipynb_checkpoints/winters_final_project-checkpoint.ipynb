{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a5c87-7904-44bc-88ce-5fa377a654b7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "- Wiley Winters\n",
    "- MSDS 686 Deep Learning\n",
    "- Week 7-8 Kaggle Project&nbsp;&mdash;&nbsp;Brain Tumor Classification\n",
    "- 2025-MAR-\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05873db-0aad-476d-8b41-bd62b38fbe2c",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b5d5-8ee4-487d-b812-9e651e8f0411",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "**Required for 80%**</p>\n",
    "Complete project on *kaggle.com* using the skills learned in the <u>Deep Learning</u> class.  The following are required:\n",
    "- Show/plot sample images or data with labels\n",
    "- Include at least on of the following\n",
    "  - Convolution\n",
    "  - Max Pooling\n",
    "  - Batch Normalization\n",
    "  - Dropout\n",
    "  - LSTM\n",
    "  - TF-IDf\n",
    "- Use validation data\n",
    "- Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333805a-2b73-4173-89af-5e8f15c229dc",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "**Additional for another 20%**</p>\n",
    "- Use data augmentation\n",
    "- Use at least one of the following:\n",
    "  - Kernels\n",
    "  - Activation functions\n",
    "  - Loss functions\n",
    "  - Libraries\n",
    "  - Methods\n",
    "- Learning rate optimization\n",
    "- Functional API model\n",
    "- Transfer learning with or without trainable parameters\n",
    "- Confusion matrix and / or ROC plots\n",
    "- Plots of accuracy/loss vs epochs\n",
    "- Show/plot sample incorrect prediction with labels and correct label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ff122-b739-4898-b7c2-7da8051f4c91",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------\n",
    "### Load Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b571d24-526c-4b90-84b1-d1f484d67a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, logging, random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# TensorFlow likes to display a lot of debug information\n",
    "# on my home system\n",
    "# I will squash the messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorFlow').setLevel(logging.FATAL)\n",
    "\n",
    "# Tensorflow and keras APIs for convoluted neural Networks (CNN)s\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.applications import Xception\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Make plots have guidelines\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Squash Python warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb16e6f-e27c-4e62-a1e0-e45be18f5204",
   "metadata": {},
   "source": [
    "**Set Random Seed for Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbe0b5-e813-4917-aadc-06cad648d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703e0d1-2a4c-40f9-ad69-f8f1a52eaef1",
   "metadata": {},
   "source": [
    "**Declare Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5498fd7-d5d9-4bce-a59a-8745b6ce98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing image directories\n",
    "home_dir = '/home/wiley'\n",
    "trn_dir = home_dir+'/regis/dataScience/msds686/week7/kaggleProject/images/data/training'\n",
    "tst_dir = home_dir+'/regis/dataScience/msds686/week7/kaggleProject/images/data/testing'\n",
    "val_dir = home_dir+'/regis/dataScience/msds686/week7/kaggleProcject/images/data/validation'\n",
    "\n",
    "# Define classes\n",
    "classes = ['negative', 'positive']\n",
    "\n",
    "# Define early_stop callback\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "# Image size and shape\n",
    "img_size = (299, 299)\n",
    "img_shape = (299, 299, 3)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08646792-0d91-4220-8db5-5e36ff566c52",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824ec9-23e7-495a-9895-7321b8861f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance Metrics\n",
    "def plot_history(history):\n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(epochs, history.history['loss'], 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'r', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(epochs, history.history['accuracy'], 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, history.history['val_accuracy'], 'r', label = 'Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(epochs, history.history['precision'], 'b', label='Training Precision')\n",
    "    plt.plot(epochs, history.history['val_precision'], 'r', label='Validation Precision')\n",
    "    plt.title('Training and Validation Precision')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(epochs, history.history['recall'], 'b', label='Training Recall')\n",
    "    plt.plot(epochs, history.history['val_recall'], 'r', label='Validation Recall')\n",
    "    plt.title('Training and Validation Recall')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle('Model Training Metrics over Epochs', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577b362-86a3-4dd5-8135-5675545b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results from test data\n",
    "def model_evaluate(model, ds):\n",
    "    score = model.evaluate(ds, verbose=1)\n",
    "    print('-' * 30)\n",
    "    print('\\033[1m'+'Test results:'+'\\033[0m')\n",
    "    print(f'Test Score: {score[0]:.4f}')\n",
    "    print('-' * 30)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e51bf-ce68-418a-95d9-e2bd061af0e5",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "The method used to load paths and classes into the dataframes will go from director to directory.  In other words, there will be artificial groupings of the different brain tumor classes.  I added statements to shuffle the values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68e32f-2bd3-45c4-a391-2830c3d44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into a pandas dataframe for EDA\n",
    "classes, paths = zip(*[(label, os.path.join(trn_dir, label, image))\n",
    "                       for label in os.listdir(trn_dir)\n",
    "                       if os.path.isdir(os.path.join(trn_dir, label))\n",
    "                       for image in os.listdir(os.path.join(trn_dir, label))])\n",
    "\n",
    "trn_df = pd.DataFrame({'paths': paths, 'classes': classes})\n",
    "\n",
    "# Load testing data into a pandas dataframe for EDA\n",
    "classes, paths = zip(*[(label, os.path.join(tst_dir, label, image))\n",
    "                       for label in os.listdir(tst_dir)\n",
    "                       if os.path.isdir(os.path.join(tst_dir, label))\n",
    "                       for image in os.listdir(os.path.join(tst_dir, label))])\n",
    "\n",
    "tst_df = pd.DataFrame({'paths': paths, 'classes': classes})\n",
    "\n",
    "# Shuffle the training and testing dataframes\n",
    "trn_df = trn_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "tst_df = tst_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Take a look at the results\n",
    "print('Training:   \\n', trn_df.head(10).to_markdown())\n",
    "print('Testing:    \\n', tst_df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c9db2-c2c8-47bd-b7e8-f8e560893cbb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c2877-8ac2-4ec1-9538-058148afa3b4",
   "metadata": {},
   "source": [
    "**Look at Training Images' Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbdfd0c-6a4f-467f-b2db-9660ef784211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "trn_df['classes'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83417025-01e6-4455-8da6-4b296105fd5b",
   "metadata": {},
   "source": [
    "The distribution is what I would expect in the real world where the majority class would be tumor free."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb58827-788f-4a7f-b3cc-d3e1c5b1794c",
   "metadata": {},
   "source": [
    "**Look at Testing Images' Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721c78-2fe1-4ead-9893-719aa5358cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "tst_df['classes'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Image Counts in Testing Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Image Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45b538-95f6-4941-b788-911279995810",
   "metadata": {},
   "source": [
    "Distribution mirrors what the *training data* shows, but with less frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9268e-735f-4c8f-8eda-b90d7766f17a",
   "metadata": {},
   "source": [
    "**Examine Shape of Training and Testing DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbc83e-c39f-4fa3-be99-77ce26ea9877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Shape: \\n', trn_df.shape)\n",
    "print('Testing Shape:  \\n', tst_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8aa5-b7de-4a72-9fcc-7621af79763f",
   "metadata": {},
   "source": [
    "**NOTE:**&nbsp;&nbsp;Since the dataframes are built from the contents of the image directories, there should be no missing values or duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e147d77-1ae2-418c-9d9a-943c6529ebc0",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ca6dd-a6b7-4bbb-b493-65a39e414d94",
   "metadata": {},
   "source": [
    "**Create a Validation Subset from Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f94b2-2e1b-4764-b361-56a1372ae55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, trn_df = train_test_split(trn_df, train_size=0.2, random_state=42,\n",
    "                                  stratify=trn_df['classes'])\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3952598-74ad-4b34-ac38-6f1738915fff",
   "metadata": {},
   "source": [
    "### Process Images from DataFrames\n",
    "I am not sure if I have enough images to effectively train my CNN model.  I am leery of rotating or flipping images during the `ImageDataGenerator()` process; therefor, I will only adjust their brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b32df-808b-4c56-a8d9-40b36d7dc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "\n",
    "gen = ImageDataGenerator(rescale=1/255, brightness_range=(0.5, 1.5))\n",
    "\n",
    "tst_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "trn_gen = gen.flow_from_dataframe(trn_df, x_col='paths', y_col='classes',\n",
    "                                  batch_size=bs, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "val_gen = gen.flow_from_dataframe(val_df, x_col='paths', y_col='classes',\n",
    "                                  batch_size=bs, target_size=img_size,\n",
    "                                  shuffle=True)\n",
    "\n",
    "tst_gen = tst_gen.flow_from_dataframe(tst_df, x_col='paths', y_col='classes',\n",
    "                                      batch_size=16, target_size=img_size,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8276ee3-e00a-476c-b651-da13679a6b9d",
   "metadata": {},
   "source": [
    "### Examine a few Images and their Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbac09-495d-47f5-9ec3-3f4b6cd79282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = trn_gen.class_indices\n",
    "classes = list(dict.keys())\n",
    "images, labels = next(tst_gen)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(image)\n",
    "    class_name = classes[np.argmax(label)]\n",
    "    plt.title(class_name, color='k', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c5b4f-ca6e-41d6-9923-ea713edb387e",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec8ba1-94e8-4796-ba7a-d2c69fcaadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "backend.clear_session()\n",
    "\n",
    "inputs  = Input(shape=(img_shape))\n",
    "rescale = Rescaling(1./255)(inputs)\n",
    "\n",
    "# Conv Layer 1\n",
    "conv1   = Conv2D(filters=28, kernel_size=5, padding='same',\n",
    "                 activation='relu')(rescale)\n",
    "pool1   = MaxPool2D()(conv1)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv2   = Conv2D(filters=56, kernel_size=5, padding='same',\n",
    "                 activation='relu')(pool1)\n",
    "pool2   = MaxPool2D()(conv2)\n",
    "\n",
    "# Conv Layer 3\n",
    "conv3   = Conv2D(filters=128, kernel_size=5, padding='same',\n",
    "                 activation='relu')(pool2)\n",
    "pool3   = MaxPool2D()(conv3)\n",
    "\n",
    "# Conv Layer 4\n",
    "conv4   = Conv2D(filters=256, kernel_size=5, padding='same',\n",
    "                 activation='relu')(pool3)\n",
    "pool4   = MaxPool2D()(conv4)\n",
    "\n",
    "# Apply Batch Normalization, Flatten, and Dense Layers\n",
    "batch3  = BatchNormalization()(pool4)\n",
    "flatten = Flatten()(batch3)\n",
    "dense   = Dense(512, activation='relu')(flatten)\n",
    "\n",
    "# Pull the model together\n",
    "preds   = Dense(num_classes, activation='softmax')(dense)\n",
    "\n",
    "model_base = Model(inputs, preds)\n",
    "\n",
    "# Compile base model\n",
    "model_base.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Print summary of model\n",
    "model_base.summary()\n",
    "\n",
    "# Plot model\n",
    "plot_model(model_base, show_shapes=True)\n",
    "\n",
    "# Fit data to model\n",
    "hist_base = model_base.fit(trn_gen, epochs=50, batch_size=128,\n",
    "                           validation_data=val_gen,\n",
    "                           callbacks=[early_stop])\n",
    "\n",
    "# Plot training results\n",
    "plot_history(hist_base)\n",
    "\n",
    "# Evaluate test data\n",
    "model_evaluate(model_base, tst_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f214d-a14a-4c7c-a757-81e9ff922ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
